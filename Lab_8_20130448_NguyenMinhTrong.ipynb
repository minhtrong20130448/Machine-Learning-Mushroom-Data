{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhtrong20130448/ML/blob/main/Lab_8_20130448_NguyenMinhTrong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task. \n",
        "\n",
        "*   **Deadline: 23:59, 17/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from prettytable import PrettyTable\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataset = datasets.load_iris()\n",
        "X = iris_dataset.data\n",
        "y = iris_dataset.target\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "            \n",
        "grid_svm = GridSearchCV(svm, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)\n",
        "grid_svm.fit(X_train,Y_train)\n",
        "y_pred_svm = grid_svm.predict(X_test)\n",
        "\n",
        "accuracy_grid_svm = round(metrics.accuracy_score(Y_test, y_pred_svm), 4)\n",
        "precision_grid_svm = round(metrics.precision_score(Y_test, y_pred_svm, average='macro'), 4)\n",
        "recall_grid_svm = round(metrics.recall_score(Y_test, y_pred_svm, average='macro'), 4)\n",
        "f1_grid_svm = round(metrics.f1_score(Y_test, y_pred_svm, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_svm);\n",
        "print('best_params: ' ,grid_svm.best_params_)\n",
        "print('best_index: ', grid_svm.best_index_)\n",
        "print('best_score: ', grid_svm.best_score_)"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f183a9a-13ad-4c69-fff9-fa0840286a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_params:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "best_index:  22\n",
            "best_score:  0.980952380952381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kNN = KNeighborsClassifier()\n",
        "\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid_kNN = GridSearchCV(kNN, grid_params, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "grid_kNN.fit(X_train,Y_train)\n",
        "y_pred_kNN = grid_kNN.predict(X_test)\n",
        "\n",
        "accuracy_grid_knn = round(metrics.accuracy_score(Y_test, y_pred_kNN), 4)\n",
        "precision_grid_knn = round(metrics.precision_score(Y_test, y_pred_kNN, average='macro'), 4)\n",
        "recall_grid_knn = round(metrics.recall_score(Y_test, y_pred_kNN, average='macro'), 4)\n",
        "f1_grid_knn = round(metrics.f1_score(Y_test, y_pred_kNN, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_knn)\n",
        "print('best_params: ' ,grid_kNN.best_params_)\n",
        "print('best_index: ' ,grid_kNN.best_index_)\n",
        "print('best_score: ' ,grid_kNN.best_score_)"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ddd2f3-f927-4dc0-ff9b-06898dfd0252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.9778\n",
            "best_params:  {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "best_index:  0\n",
            "best_score:  0.961904761904762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "3lQSOcjL_TIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "grid_rf = GridSearchCV(rf, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "grid_rf.fit(X_train,Y_train)\n",
        "y_pred_rf = grid_rf.predict(X_test)\n",
        "\n",
        "accuracy_grid_rf = round(metrics.accuracy_score(Y_test, y_pred_rf), 4)\n",
        "precision_grid_rf = round(metrics.precision_score(Y_test, y_pred_rf, average='macro'), 4)\n",
        "recall_grid_rf = round(metrics.recall_score(Y_test, y_pred_rf, average='macro'), 4)\n",
        "f1_grid_rf = round(metrics.f1_score(Y_test, y_pred_rf, average='macro'), 4)\n"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vẽ bảng so sánh\n",
        "table = PrettyTable(['Thuật toán','Acc','Pre','Recall','F1'])\n",
        "table.add_row(['SVM', accuracy_grid_svm, precision_grid_svm, recall_grid_svm, f1_grid_svm])\n",
        "table.add_row(['kNN', accuracy_grid_knn, precision_grid_knn, recall_grid_knn, f1_grid_knn])\n",
        "table.add_row(['RandomForest', accuracy_grid_rf, precision_grid_rf, recall_grid_rf, f1_grid_rf])\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DrWqUJGofAd",
        "outputId": "a40d4613-c776-4f1d-d10d-2b4fd1f3e4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------+--------+--------+--------+\n",
            "|  Thuật toán  |  Acc   |  Pre   | Recall |   F1   |\n",
            "+--------------+--------+--------+--------+--------+\n",
            "|     SVM      | 0.9778 | 0.9722 | 0.9815 | 0.976  |\n",
            "|     kNN      | 0.9778 | 0.9722 | 0.9815 | 0.976  |\n",
            "| RandomForest | 0.9556 | 0.9512 | 0.9512 | 0.9512 |\n",
            "+--------------+--------+--------+--------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM** \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_dataset = datasets.load_breast_cancer()\n",
        "X = cancer_dataset.data\n",
        "y = cancer_dataset.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.05, test_size=0.05, random_state=42)\n",
        "\n",
        "svm = SVC()\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "grid_svm = GridSearchCV(svm, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)\n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svm = grid_svm.predict(X_test)\n",
        "\n",
        "accuracy_grid_svm = round(metrics.accuracy_score(y_test, y_pred_svm), 4)\n",
        "precision_grid_svm = round(metrics.precision_score(y_test, y_pred_svm, average='macro'), 4)\n",
        "recall_grid_svm = round(metrics.recall_score(y_test, y_pred_svm, average='macro'), 4)\n",
        "f1_grid_svm = round(metrics.f1_score(y_test, y_pred_svm, average='macro'), 4)\n",
        "\n",
        "print(\"best parameters: \", grid_svm.best_params_)\n",
        "print('best_score: ', grid_svm.best_score_)\n",
        "print(\"accuracy: \", accuracy_grid_svm)"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e9bab0-2278-4dd5-8e6a-81d353bafd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best parameters:  {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
            "best_score:  1.0\n",
            "accuracy:  0.9655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN** "
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kNN = KNeighborsClassifier()\n",
        "\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid_kNN = GridSearchCV(kNN, grid_params, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "grid_kNN.fit(X_train,y_train)\n",
        "y_pred_kNN = grid_kNN.predict(X_test)\n",
        "\n",
        "accuracy_grid_knn = round(metrics.accuracy_score(y_test, y_pred_kNN), 4)\n",
        "precision_grid_knn = round(metrics.precision_score(y_test, y_pred_kNN, average='macro'), 4)\n",
        "recall_grid_knn = round(metrics.recall_score(y_test, y_pred_kNN, average='macro'), 4)\n",
        "f1_grid_knn = round(metrics.f1_score(y_test, y_pred_kNN, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_knn)\n",
        "print('best_params: ' ,grid_kNN.best_params_)\n",
        "print('best_score: ' ,grid_kNN.best_score_)"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0959e2c3-6266-4307-dd65-3a7917b0afbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.931\n",
            "best_params:  {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "best_score:  0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression** "
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgr = LogisticRegression()\n",
        "\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_lgr = GridSearchCV(lgr, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "\n",
        "grid_lgr.fit(X_train,y_train)\n",
        "y_pred_lgr = grid_lgr.predict(X_test)\n",
        "\n",
        "accuracy_grid_lgr = round(metrics.accuracy_score(y_test, y_pred_lgr), 4)\n",
        "precision_grid_lgr = round(metrics.precision_score(y_test, y_pred_lgr, average='macro'), 4)\n",
        "recall_grid_lgr = round(metrics.recall_score(y_test, y_pred_lgr, average='macro'), 4)\n",
        "f1_grid_lgr = round(metrics.f1_score(y_test, y_pred_lgr, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_lgr)\n",
        "print('best_params: ' ,grid_lgr.best_params_)\n",
        "print('best_score: ' ,grid_lgr.best_score_)"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cab53a0-6dd0-4012-c92a-d6f433a00f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8276\n",
            "best_params:  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "best_score:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest** "
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "grid_rf = GridSearchCV(rf, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "grid_rf.fit(X_train,y_train)\n",
        "y_pred_rf = grid_rf.predict(X_test)\n",
        "\n",
        "accuracy_grid_rf = round(metrics.accuracy_score(y_test, y_pred_rf), 4)\n",
        "precision_grid_rf = round(metrics.precision_score(y_test, y_pred_rf, average='macro'), 4)\n",
        "recall_grid_rf = round(metrics.recall_score(y_test, y_pred_rf, average='macro'), 4)\n",
        "f1_grid_rf = round(metrics.f1_score(y_test, y_pred_rf, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_rf)\n",
        "print('best_params: ' ,grid_rf.best_params_)\n",
        "print('best_score: ' ,grid_rf.best_score_)"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f396379-dbc7-4d62-ee00-7dac7575671e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.9655\n",
            "best_params:  {'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 3, 'n_estimators': 25}\n",
            "best_score:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vẽ bảng so sánh\n",
        "table = PrettyTable(['Thuật toán','Acc','Pre','Recall','F1'])\n",
        "table.add_row(['SVM', accuracy_grid_svm, precision_grid_svm, recall_grid_svm, f1_grid_svm])\n",
        "table.add_row(['kNN', accuracy_grid_knn, precision_grid_knn, recall_grid_knn, f1_grid_knn])\n",
        "table.add_row(['Logistic', accuracy_grid_lgr, precision_grid_lgr, recall_grid_lgr, f1_grid_lgr])\n",
        "table.add_row(['RandomForest', accuracy_grid_rf, precision_grid_rf, recall_grid_rf, f1_grid_rf])\n",
        "print(table)"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feeccf53-8d85-463b-c259-5e65a73e1e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------+--------+--------+--------+\n",
            "|  Thuật toán  |  Acc   |  Pre   | Recall |   F1   |\n",
            "+--------------+--------+--------+--------+--------+\n",
            "|     SVM      | 0.9655 | 0.9737 | 0.9545 | 0.9627 |\n",
            "|     kNN      | 0.931  |  0.95  | 0.9091 | 0.9237 |\n",
            "|   Logistic   | 0.8276 | 0.8913 | 0.7727 | 0.792  |\n",
            "| RandomForest | 0.9655 | 0.9737 | 0.9545 | 0.9627 |\n",
            "+--------------+--------+--------+--------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion. \n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')\n",
        "#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b4a069-af0b-454f-95de-b4d1c8960535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466be750-8de5-408c-e491-c3c1cdffbbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29fec26-65a6-44bc-dfb0-3ff2a6bee6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eddc27f-0812-45ea-fad7-4a5153cb89e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, train_size=0.5,test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12663a7-f19a-43d6-b656-f66bc1941a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 504, 'neg': 496})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.6. Apply **SVM** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "            \n",
        "grid_svm = GridSearchCV(svm, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)\n",
        "grid_svm.fit(X_train_bow,y_train)\n",
        "y_pred_svm = grid_svm.predict(X_test_bow)\n",
        "\n",
        "accuracy_grid_svm = round(metrics.accuracy_score(y_test, y_pred_svm), 4)\n",
        "precision_grid_svm = round(metrics.precision_score(y_test, y_pred_svm, average='macro'), 4)\n",
        "recall_grid_svm = round(metrics.recall_score(y_test, y_pred_svm, average='macro'), 4)\n",
        "f1_grid_svm = round(metrics.f1_score(y_test, y_pred_svm, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_svm);\n",
        "print('best_params: ' ,grid_svm.best_params_)\n",
        "print('best_index: ', grid_svm.best_index_)\n",
        "print('best_score: ', grid_svm.best_score_)\n"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211067c0-2c8c-4d90-99b5-3ae80edabae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8197\n",
            "best_params:  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "best_index:  34\n",
            "best_score:  0.849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.7. Apply **RandomForest** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "grid_rf = GridSearchCV(rf, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "grid_rf.fit(X_train_bow, y_train)\n",
        "y_pred_rf = grid_rf.predict(X_test_bow)\n",
        "\n",
        "accuracy_grid_rf = round(metrics.accuracy_score(y_test, y_pred_rf), 4)\n",
        "precision_grid_rf = round(metrics.precision_score(y_test, y_pred_rf, average='macro'), 4)\n",
        "recall_grid_rf = round(metrics.recall_score(y_test, y_pred_rf, average='macro'), 4)\n",
        "f1_grid_rf = round(metrics.f1_score(y_test, y_pred_rf, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_rf)\n",
        "print('best_params: ' ,grid_rf.best_params_)\n",
        "print('best_score: ' ,grid_rf.best_score_)"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b51f3d-5552-47af-8e7a-17433c43d77f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.7364\n",
            "best_params:  {'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': 6, 'n_estimators': 50}\n",
            "best_score:  0.753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.8. Apply **kNN** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kNN = KNeighborsClassifier()\n",
        "\n",
        "grid_params = { 'n_neighbors' : [7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid_kNN = GridSearchCV(kNN, grid_params, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "grid_kNN.fit(X_train_bow,y_train)\n",
        "y_pred_kNN = grid_kNN.predict(X_test_bow)\n",
        "\n",
        "accuracy_grid_knn = round(metrics.accuracy_score(y_test, y_pred_kNN), 4)\n",
        "precision_grid_knn = round(metrics.precision_score(y_test, y_pred_kNN, average='macro'), 4)\n",
        "recall_grid_knn = round(metrics.recall_score(y_test, y_pred_kNN, average='macro'), 4)\n",
        "f1_grid_knn = round(metrics.f1_score(y_test, y_pred_kNN, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_knn)\n",
        "print('best_params: ' ,grid_kNN.best_params_)\n",
        "print('best_index: ' ,grid_kNN.best_index_)\n",
        "print('best_score: ' ,grid_kNN.best_score_)"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76b740b-f70e-48a8-9e13-d2f940676a08"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.6091\n",
            "best_params:  {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
            "best_index:  4\n",
            "best_score:  0.6459999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.9. Apply **LogisticRegression** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgr = LogisticRegression()\n",
        "\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_lgr = GridSearchCV(lgr, param_grid, scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)  \n",
        "\n",
        "grid_lgr.fit(X_train_bow,y_train)\n",
        "y_pred_lgr = grid_lgr.predict(X_test_bow)\n",
        "\n",
        "accuracy_grid_lgr = round(metrics.accuracy_score(y_test, y_pred_lgr), 4)\n",
        "precision_grid_lgr = round(metrics.precision_score(y_test, y_pred_lgr, average='macro'), 4)\n",
        "recall_grid_lgr = round(metrics.recall_score(y_test, y_pred_lgr, average='macro'), 4)\n",
        "f1_grid_lgr = round(metrics.f1_score(y_test, y_pred_lgr, average='macro'), 4)\n",
        "\n",
        "print('accuracy: ', accuracy_grid_lgr)\n",
        "print('best_params: ' ,grid_lgr.best_params_)\n",
        "print('best_score: ' ,grid_lgr.best_score_)"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5875a861-c5ac-430f-ad5d-8618af3cbb5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8136\n",
            "best_params:  {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
            "best_score:  0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vẽ bảng so sánh\n",
        "table = PrettyTable(['Thuật toán','Acc','Pre','Recall','F1'])\n",
        "table.add_row(['SVM', accuracy_grid_svm, precision_grid_svm, recall_grid_svm, f1_grid_svm])\n",
        "table.add_row(['kNN', accuracy_grid_knn, precision_grid_knn, recall_grid_knn, f1_grid_knn])\n",
        "table.add_row(['Logistic', accuracy_grid_lgr, precision_grid_lgr, recall_grid_lgr, f1_grid_lgr])\n",
        "table.add_row(['RandomForest', accuracy_grid_rf, precision_grid_rf, recall_grid_rf, f1_grid_rf])\n",
        "print(table)"
      ],
      "metadata": {
        "id": "F2MXnAkADnli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a83c11-caf9-4f19-f4fc-b48b1ba5f6ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------+--------+--------+--------+\n",
            "|  Thuật toán  |  Acc   |  Pre   | Recall |   F1   |\n",
            "+--------------+--------+--------+--------+--------+\n",
            "|     SVM      | 0.8197 | 0.8199 | 0.8195 | 0.8196 |\n",
            "|     kNN      | 0.6091 | 0.6467 | 0.6059 | 0.5784 |\n",
            "|   Logistic   | 0.8136 | 0.8139 | 0.8134 | 0.8135 |\n",
            "| RandomForest | 0.7364 | 0.7418 | 0.7354 | 0.7343 |\n",
            "+--------------+--------+--------+--------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}